"""
This module provides functionality for interacting with OpenAI's ChatGPT asynchronously,
enabling session-based conversation management and enhanced prompt augmentation.

### Overview
The module implements a `ChatGPTClient` class designed to:
- Manage session-specific conversation histories.
- Augment user prompts with contextual information using the `AugmentPrompt` utility.
- Send asynchronous requests to the OpenAI ChatCompletion API and handle responses.
"""

import os
from openai import AsyncOpenAI


api_key = os.getenv("OPENAI_API_KEY")
aclient = AsyncOpenAI(api_key=api_key)  # Ensure you have: pip install --upgrade openai


from augment_prompt import AugmentPrompt
from db_operations import DBOperations
from utils import ParseResponse


# --- ChatGPT Client (Asynchronous) ---
class ChatGPTClient:
    """
    A client for interacting with OpenAI's ChatGPT asynchronously.

    This class manages session-based interactions with ChatGPT, including:
    - Maintaining user-specific conversation history.
    - Augmenting prompts with contextual information.
    - Sending requests to OpenAI asynchronously and managing responses.

    Attributes:
        augmentor (AugmentPrompt): A utility to generate augmented prompts.
        user_sessions (dict): Stores session-specific conversation history.
    """

    def __init__(self):
        """
        Initialize the ChatGPTClient with an augmentor and a session manager.
        """
        self.augmentor = AugmentPrompt()
        self.db_operations = DBOperations()
        self.user_sessions = {}
        self.parser = ParseResponse()
        self._max_len = 50 * 2  # Last 50 interactions (includes one user
                                # entry + one corresponding to GPT response)

    def update_correspondence(self, session_id, message, is_user, clean=False):
        """
        Update the conversation history for a given session.

        Depending on the `clean` flag, this method either stores the raw user
        message or an augmented version with additional context.

        Args:
            session_id (str): The unique identifier for the user's session.
            message (str): The message content to be stored.
            is_user (bool): Whether the message is from the user (`True`)
            or the assistant (`False`).
            clean (bool): Whether to store the raw message (`True`) or an
            augmented version (`False`).

        Notes:
            - Limits conversation history to the last 5 entries to avoid
              memory overload.
            - Augments messages with prior book recommendations if `clean` is
              `False`.
        """

        if (session_id not in self.user_sessions
                or not self.user_sessions[session_id]):
            # Initializing with an empty list
            self.user_sessions[session_id] = []

        if is_user:
            if not clean:
                content = self.augmentor.generate(message)
            else:
                content = message
        else:
            parsed = self.parser.run(message)
            content = ""
            if parsed.is_json:
                if "books" in parsed.data:
                    if parsed.data["books"]:
                        content = "Suggested books are:\n\n"
                        for book in parsed.data["books"]:
                            if "author_name" in book and "title" in book:
                                content += (
                                    f"- 'title': \"{book['title']}\","
                                    f"'author_name': {book['author_name']}\n")
                elif "no_matches_found" in parsed.data["no_matches_found"]:
                    content = parsed["no_matches_found"]
                elif "profanity_found" in parsed.data:
                    content = parsed["profanity_found"]

        self.user_sessions[session_id].append({
            "role": "user" if is_user else "assistant",
            "content": content
        })

    async def send_prompt(self, session_id, message):
        """
        Send a user prompt to ChatGPT and retrieve the assistant's response.

        This method:
        - Augments the user's prompt with context if necessary.
        - Sends the prompt to OpenAI's ChatCompletion API asynchronously.
        - Stores the assistant's response in the session history.

        Args:
            session_id (str): The unique identifier for the user's session.
            message (str): The user's prompt or message.

        Returns:
            str: The response generated by ChatGPT.

        Raises:
            Exception: If the OpenAI API request fails.
        """

        self.user_sessions[session_id] = self.db_operations.retrieve(
            session_id)

        # 1) Add augmented message (clean=False)
        self.update_correspondence(
            session_id, message, is_user=True, clean=False)

        # 2) Call ChatCompletion asynchronously
        response = await aclient.chat.completions.create(
            model="gpt-4o",
            messages=self.user_sessions[session_id],
            temperature=1,
        )

        # 3) Remove the last augmented message
        self.user_sessions[session_id].pop()

        # 4) Add user message as-is
        self.update_correspondence(
             session_id, message, is_user=True, clean=True)

        # 5) Extract and store assistant's reply
        reply = response.choices[0].message.content
        self.update_correspondence(
            session_id, reply, is_user=False)

        if len(self.user_sessions[session_id]) >= self._max_len:
            # Cutting the oldest interaction between user and GPT API
            self.user_sessions[session_id] = self.user_sessions[session_id][2:]

        self.db_operations.upsert(
            session_id,
            self.user_sessions[session_id])

        return reply
